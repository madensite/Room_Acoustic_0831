# 룸 어쿠스틱 측정 앱: 프로젝트 요약

## 1. 프로젝트 개요

이 애플리케이션은 사용자의 방 환경을 분석하여 최적의 사운드 환경을 조성할 수 있도록 돕는 **룸 어쿠스틱 측정 및 분석 도구**입니다.

주요 기능은 다음과 같습니다.

*   **실시간 스피커 탐지:** 딥러닝 모델(YOLOv8)을 사용하여 카메라 화면에서 실시간으로 스피커를 찾아냅니다.
*   **AI 챗봇 상담:** 측정된 데이터를 기반으로, 더 나은 사운드 환경을 만들기 위한 방법을 AI 챗봇과 상담할 수 있습니다.
*   **측정 데이터 관리:** 여러 개의 방 정보를 저장하고, 언제든지 다시 확인하거나 재측정, 또는 대화 내용을 이어갈 수 있습니다.

## 2. 사용된 핵심 기술

이 프로젝트는 다음과 같은 최신 기술들을 활용하여 제작되었습니다.

*   **UI (사용자 인터페이스):**
    *   **Jetpack Compose:** Google의 최신 UI 개발 도구입니다. 더 적은 코드로 깔끔하고 반응성이 뛰어난 화면을 만들 수 있습니다.
*   **AI (인공지능):**
    *   **TensorFlow Lite & YOLOv8:** 스피커를 탐지하기 위한 딥러닝 모델입니다. `best_int8.tflite` 라는 모델 파일을 사용하여, 스마트폰 카메라 화면에서 실시간으로 스피커 객체를 찾아냅니다.
    *   **OpenAI (GPT-4o-mini):** AI 챗봇 기능에 사용됩니다. 측정된 방 데이터를 기반으로 사용자에게 맞춤형 음향 컨설팅을 제공합니다.
*   **카메라 제어:**
    *   **CameraX:** 카메라 미리보기 화면을 표시하고, 이미지 프레임을 실시간으로 분석(스피커 탐지)하는 데 사용되는 라이브러리입니다.
*   **데이터베이스:**
    *   **Room:** 측정된 방 정보(이름, 측정 완료 여부, 대화 내용 등)를 스마트폰 내부에 안전하게 저장하고 관리하기 위해 사용됩니다.
*   **네트워크 통신:**
    *   **Retrofit:** OpenAI 서버와 통신하여 GPT 모델의 답변을 받아오는 역할을 합니다.
*   **화면 이동 (내비게이션):**
    *   **Jetpack Navigation (Compose):** 앱 내의 여러 화면(Screen) 간의 이동을 체계적으로 관리합니다.

## 3. 앱 권한

이 앱은 핵심 기능을 제공하기 위해 다음과 같은 권한을 사용자에게 요청합니다.

*   **카메라 (`android.permission.CAMERA`):** 스피커를 탐지하기 위해 필수적입니다.
*   **인터넷 (`android.permission.INTERNET`):** AI 챗봇(OpenAI)과 통신하기 위해 필요합니다.
*   **녹음 (`android.permission.RECORD_AUDIO`):** (현재 코드상에서는 녹음 기능이 활성화되어 있지는 않지만) 향후 방의 울림(잔향)을 측정하는 기능을 위해 포함되어 있습니다.

## 4. 화면 흐름 및 UI 구조

앱을 실행했을 때 사용자가 보게 되는 화면과 그 흐름은 다음과 같습니다.

1.  **스플래시 화면 (`SplashScreen`):**
    *   앱이 처음 시작될 때 잠시 나타나는 로고 화면입니다. 1초 후에 자동으로 다음 화면으로 넘어갑니다.

2.  **방 목록 화면 (`RoomScreen`):**
    *   **역할:** 사용자가 생성한 모든 '방'의 목록을 보여주는 메인 화면입니다.
    *   **프로세스:**
        *   화면 우측 하단의 플로팅 버튼을 눌러 '새 방 만들기'를 할 수 있습니다.
        *   각 방 항목에는 측정 완료 여부와 대화 여부가 칩(Chip) 형태로 표시됩니다.
        *   **짧게 터치:** 방을 측정하거나, AI 챗봇과 대화를 시작하는 메뉴가 나타납니다.
        *   **길게 터치:** 방 이름을 바꾸거나, 재측정, 대화 내용 초기화, 방 삭제 등의 관리 메뉴가 나타납니다.

3.  **측정 플로우 (여러 화면의 연속 과정):**
    *   '측정 시작'을 누르면 다음 순서대로 화면이 진행됩니다.
    *   **① 스피커 탐지 화면 (`MeasureScreen`):**
        *   카메라 미리보기가 나타나고, YOLOv8 모델이 실시간으로 스피커를 찾습니다.
        *   카메라 화면 위에 스피커가 탐지되면 초록색 사각형(`BoundingBox`)이 그려집니다.
        *   일정 시간 동안 안정적으로 스피커가 탐지되면 자동으로 다음 단계로 넘어갑니다. 만약 스피커를 찾지 못하면, 재시도하거나 그냥 넘어갈지 묻는 대화상자가 나타납니다.
    *   **② 탐지 결과 표시 화면 (`RenderScreen`):**
        *   앞선 단계에서 스피커 탐지에 성공했는지, 실패했는지를 텍스트로 간단히 보여줍니다.
    *   **③ 녹음 가이드 화면 (`TestGuideScreen`):**
        *   (현재는 플레이스홀더) 향후 마이크를 이용한 소리 측정 방법을 안내하는 화면이 될 것입니다.
    *   **④ 녹음 진행 화면 (`KeepTestScreen`):**
        *   (현재는 플레이스홀더) 실제로 소리를 녹음하거나 분석하는 과정이 진행될 화면입니다.
    *   **⑤ 분석 완료 화면 (`AnalysisScreen`):**
        *   모든 측정이 완료되었음을 알리고, '완료' 버튼을 누르면 모든 측정 데이터를 저장한 후 메인 화면(`RoomScreen`)으로 돌아갑니다.

4.  **AI 챗봇 화면 (`ChatScreen`):**
    *   **역할:** 측정된 방 데이터를 바탕으로 OpenAI의 GPT 모델과 대화하는 화면입니다.
    *   **프로세스:**
        *   `assets/prompt/prompt001.txt` 파일에 미리 정의된 시스템 프롬프트(GPT의 역할과 지침)와 사용자의 질문을 함께 OpenAI 서버로 전송합니다.
        *   서버로부터 받은 답변을 화면에 표시합니다.
        *   사용자와 GPT의 대화는 말풍선 형태로 보여집니다.

## 5. 주요 클래스 및 파일 설명

프로젝트를 구성하는 핵심 파일들의 역할은 다음과 같습니다.

### 5.1. 화면 (UI) - `screens` 패키지

*   `MainActivity.kt`: 앱의 진입점. Jetpack Navigation을 설정하여 모든 화면의 경로를 정의하고 관리하는 가장 중요한 파일입니다.
*   `SplashScreen.kt`: 앱 시작 시 보여주는 로고 화면 UI.
*   `room/RoomScreen.kt`: 저장된 방 목록을 보여주고, 새 방을 만들거나 기존 방을 관리하는 메인 화면 UI.
*   `measure/MeasureScreen.kt`: CameraX를 사용하여 카메라 영상을 보여주고, 실시간으로 YOLOv8 모델을 돌려 스피커를 탐지하는 핵심 로직이 담긴 화면.
*   `measure/RenderScreen.kt`: 스피커 탐지 성공/실패 결과를 보여주는 화면.
*   `chat/ChatScreen.kt`: AI 챗봇과 대화하는 UI. 사용자 입력을 받고, `ChatViewModel`을 통해 GPT 응답을 요청하고 표시합니다.
*   `components/`: `StatusChips.kt` (측정/대화 상태 표시), `HandMotionView.kt` (AR 안내 애니메이션) 등 여러 화면에서 공통으로 사용하는 작은 UI 조각들.
*   `dialog/`: `EditRoomDialog.kt` (방 이름 입력/수정), `InfoDialog.kt` (정보 표시) 등 대화상자 UI.

### 5.2. 데이터 관리 - `data`, `repo`, `viewmodel` 패키지

*   `data/RoomEntity.kt`: 데이터베이스에 저장될 '방' 정보의 구조를 정의합니다. (ID, 이름, 측정 여부, 대화 내용 등)
*   `data/RoomDao.kt`: 데이터베이스에 데이터를 읽고, 쓰고, 수정하고, 삭제하는 명령어(SQL 쿼리)를 정의하는 인터페이스.
*   `data/AppDatabase.kt`: Room 데이터베이스 자체를 생성하고 관리하는 클래스.
*   `repo/RoomRepository.kt`: UI와 데이터베이스 사이의 중개자. UI가 데이터에 직접 접근하지 않고, 이 Repository를 통해 데이터를 요청하도록 구조를 정리해줍니다.
*   `viewmodel/RoomViewModel.kt`: `RoomScreen`과 측정 플로우 화면들에서 필요한 데이터(방 목록, 현재 선택된 방 ID, 측정 결과 등)를 관리하고, UI가 변경되어도 데이터를 안전하게 보존하는 역할.
*   `viewmodel/ChatViewModel.kt`: `ChatScreen`에서 필요한 데이터(대화 내용)를 관리하고, OpenAI에 답변을 요청하는 로직을 처리합니다.

### 5.3. AI 모델 (YOLOv8) - `yolo` 패키지

*   `Detector.kt`: TensorFlow Lite 모델(`best_int8.tflite`)을 로드하고, 카메라로부터 받은 이미지를 입력으로 넣어 스피커를 탐지하는 핵심 클래스. 탐지 결과(BoundingBox)를 계산하고, NMS(Non-Maximum Suppression) 알고리즘으로 가장 확률 높은 결과만 필터링합니다.
*   `BoundingBox.kt`: 탐지된 객체(스피커)의 위치(좌표), 크기, 신뢰도 점수, 클래스 이름을 담는 데이터 클래스.
*   `OverlayView.kt`: `MeasureScreen`의 카메라 미리보기 화면 위에, 탐지된 스피커의 위치에 맞춰 사각형을 그려주는 커스텀 View.
*   `Constants.kt`: 모델 파일 경로(`best_int8.tflite`)와 라벨 파일 경로(`labels.txt`) 등 상수 값을 저장합니다.

### 5.4. 네트워크 및 API - `api`, `model`, `util` 패키지

*   `api/OpenAIApi.kt`: Retrofit 라이브러리가 OpenAI 서버와 통신할 때 사용하는 API 명세.
*   `util/RetrofitClient.kt`: Retrofit 인스턴스를 생성하여 어디서든 `OpenAIApi`를 사용할 수 있게 해주는 싱글턴 객체.
*   `model/GPTRequest.kt`, `model/GPTResponse.kt`: OpenAI API에 요청하고 응답받을 때 사용하는 데이터의 형식을 정의합니다.

## 6. 빌드 및 실행 방법

이 프로젝트를 빌드하고 실행하려면 다음 환경이 필요합니다.

*   **Android Studio:** 최신 버전의 Android Studio 설치가 필요합니다.
*   **ARCore 지원 기기:** AR 기능을 사용하므로, ARCore를 지원하는 실제 안드로이드 기기가 필요합니다. (에뮬레이터에서는 실행이 어려울 수 있습니다.)
*   **OpenAI API 키:** AI 챗봇 기능을 사용하려면 OpenAI에서 발급받은 API 키가 필요합니다. 프로젝트 루트 디렉토리에 `local.properties` 파일을 만들고, 그 안에 `OPENAI_API_KEY="sk-..."` 형식으로 자신의 키를 추가해야 합니다.

빌드 및 실행은 Android Studio에서 프로젝트를 열고, 상단의 'Run' 버튼(▶)을 누르면 연결된 기기에 앱이 설치되고 실행됩니다. 또는, 터미널에서 `./gradlew installDebug` 명령어를 사용하여 빌드 및 설치할 수 있습니다.